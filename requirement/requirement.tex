% ------------------------------------------------
% Page start
% ------------------------------------------------
\chapter{Requirement}
\label{chapter:requirement}

\baselineskip=26pt
\thispagestyle{empty}
% ------------------------------------------------

Although Li's Hash is design for all key-value stores, but still Li's Hash is need to work basic on some requirements:

\begin{enumerate}

\item \textbf{No limited key's length}\\
For some key-value stores has limited the key length such as only 255 long (like ArangoDB \cite{web:arangodb:comparison}), this will limited the upper application's key design, this is not a good thing that limit an application what it can do only.\\

Like LevelDB \cite{web:leveldb:home-page} and Voldemort \cite{web:voldemort:any-limit-store-key} which keep the keys and values as byte arrays which means it has no limited the length.

\item \textbf{A suitable value's length}\\
The value's length of the back-end database can't too short, at least 4096 bytes long. Li's Hash design the length of value which default set the maximum size as 4096 bytes, if input value is longer than 4096 bytes, it will cut it into multi-key for storing it.\\

 This value should be not set too large such as 128 MB, which is because if the size is too large that every searching is need to allocate the same amount of memory to read the data in value, unless the hardware have a huge memory space, otherwise in the multithread environment it can out of memory. Also reading a huge data from disk will increase the I/O times.

\item \textbf{Unlimited key's amount}\\
Limited the amount of key is as same as limited the row in table in the relational database, normally this should not happed but it happened in the storage engine of Apache Cassandra which set the maximum number of cells (rows x columns) in a single partition (table) is 2 billion \cite{web:cassandra:limitations}.\\

Therefore if we use key-value pair (rows x 1 column) to think it, it still got 2 billion keys on it. It may seem very enough to many application, but the problem is this will force some application which generate more than 2 billion keys per day or per hour (such as finance information, log data, astronomy data, etc.) need to modify their source code to fit into the database, although there is many way to modify it, but it still increased the programmer's work, and this is one of the wish that Li's Hash want to solve.

\end{enumerate}

\clearpage

% ------------------------------------------------
% End of page
% ------------------------------------------------
